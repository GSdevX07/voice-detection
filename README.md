# ğŸ™ï¸ AI Voice Detection API (Deepfake vs Human)

This project is a **REST APIâ€“based AI Voice Detection system** that detects whether a given audio sample is **AI-generated or Human speech**.  
It also performs **language detection** and returns a structured JSON output as required by the problem statement.

The system is built using:
- **AASIST** (state-of-the-art audio anti-spoofing model)
- **Ensemble Learning** (AASIST + secondary ML model)
- **Whisper** for language detection
- **FastAPI** for REST API deployment

---

## ğŸš€ Features

- âœ… Accepts **Base64 encoded MP3 audio**
- âœ… Automatically converts MP3 â†’ WAV
- âœ… Detects **spoken language**
- âœ… Classifies audio as **AI_GENERATED / HUMAN**
- âœ… Provides **confidence score**
- âœ… Returns **model insights**
- âœ… Fully exposed via **REST API endpoint**

---

## ğŸ“¥ Input Format (API Request)

**Endpoint**
POST /api/voice-detection



**Headers**
x-api-key: sk_test_123456789
Content-Type: application/json



**Request Body**
```json
{
  "language": "auto",
  "audioFormat": "mp3",
  "audioBase64": "<BASE64_ENCODED_AUDIO>"
}
ğŸ“¤ Output Format (API Response)
{
  "language": "English",
  "final_classification": "AI_GENERATED",
  "confidenceScore": 0.96,
  "modelInsights": [
    "high pitch consistency",
    "lack of natural pauses",
    "vocoder artifacts detected"
  ]
}


âš™ï¸ How to Run the Project (Judges)
1ï¸âƒ£ Create Virtual Environment
python -m venv venv
venv\Scripts\activate
2ï¸âƒ£ Install Dependencies
pip install -r requirements.txt
3ï¸âƒ£ Run API Server
cd aasist
uvicorn api:app --host 0.0.0.0 --port 8000
4ï¸âƒ£ Open API Docs
http://127.0.0.1:8000/docs


ğŸ§  Models Used
ğŸ”¹ AASIST
Deep anti-spoofing neural network
Detects synthetic / converted speech

ğŸ”¹ Secondary Model (Model-2)
Trained on mixed human & AI samples
Adds robustness via ensemble decision

ğŸ”¹ Language Detection
Powered by OpenAI Whisper
Supports: English, Hindi, Tamil, Telugu, Malayalam



ğŸ—‚ï¸ Project Structure
voice-detection/
â”‚
â”œâ”€â”€ aasist/
â”‚   â”œâ”€â”€ api.py                # FastAPI endpoint
â”‚   â”œâ”€â”€ infer_single.py       # Inference pipeline
â”‚   â”œâ”€â”€ ensemble_detector.py # Ensemble logic
â”‚   â”œâ”€â”€ models/               # AASIST weights
â”‚
â”œâ”€â”€ model2/
â”‚   â””â”€â”€ wav2vec_detector.py   # Secondary model
â”‚
â”œâ”€â”€ convert_mp3_to_wav.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md


ğŸ” API Key Note
A demo API key is used for hackathon testing:
sk_test_123456789
In production, this should be stored securely (env variable).


ğŸ“š Acknowledgements & Research Credit
This project is built on top of the following research work:

AASIST: Audio Anti-Spoofing using Integrated Spectro-Temporal Graph Attention Networks
https://arxiv.org/abs/2110.01200

Original AASIST repository and ASVspoof datasets were used for model design inspiration and benchmarking.

